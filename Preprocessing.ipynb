{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import textgrid\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all dictories and file names of files with certain suffix\n",
    "def get_filelist(dir, Filelist, namelist, suffix):\n",
    "    newDir = dir\n",
    "    if os.path.isfile(dir):\n",
    "        if dir.endswith(suffix):\n",
    "            Filelist.append(dir)\n",
    "            name = os.path.basename(dir)\n",
    "            namelist.append(name[:(len(name)-len(suffix))])\n",
    "    elif os.path.isdir(dir):\n",
    "        for s in os.listdir(dir):\n",
    "            newDir=os.path.join(dir,s)\n",
    "            get_filelist(newDir, Filelist, namelist,suffix)\n",
    "    return Filelist, namelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some random chosen keywords\n",
    "KEYWORDS = ['was','his','which','from','any','she','people','without','little','about']\n",
    "\n",
    "root_dir = './LibriSpeech/Librispeech' # Root directory of audios\n",
    "text_dir = './librispeech_MFA/Documents/aligned_librispeech' # Root directory of transcripts generated by MFA\n",
    "filelist, namelist = get_filelist(root_dir,[],[],'.wav')\n",
    "scriptlist, scriptname = get_filelist(text_dir,[],[],'.TextGrid')\n",
    "\n",
    "# Generate a folder for outputs\n",
    "if os.path.exists('./Outputs') == False:\n",
    "    os.mkdir('./Outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files are generated successifully!\n"
     ]
    }
   ],
   "source": [
    "for word_idx in range(len(KEYWORDS)): #loop over all selected keywords\n",
    "    keyword = KEYWORDS[word_idx]\n",
    "    \n",
    "    filecount = 0\n",
    "\n",
    "    for file in range(len(filelist)): # loop over all audio files\n",
    "        file_dir = filelist[file]\n",
    "        file_name = namelist[file]\n",
    "        script_dir = scriptlist[file]\n",
    "\n",
    "        tg = textgrid.TextGrid()\n",
    "        tg.read(script_dir.format(file_name))\n",
    "\n",
    "        segmentlist = np.array([[0,0]])\n",
    "        locations = np.array([[0,0]])\n",
    "\n",
    "        for idx in range(0,len(tg.tiers[0])): # loop over all words in an audio\n",
    "            if tg.tiers[0][idx].mark == keyword:\n",
    "                t_start = tg.tiers[0][idx].minTime\n",
    "                t_end = tg.tiers[0][idx].maxTime\n",
    "                duration = t_end - t_start\n",
    "                \n",
    "                # Generate 1-sec segments\n",
    "                if (1-duration) >= t_start:\n",
    "                    rand_num = round(random.uniform(0,t_start),2)\n",
    "                else:\n",
    "                    rand_num = round(random.uniform(0,1-duration),2)\n",
    "\n",
    "                t_start_new = t_start - rand_num\n",
    "                t_end_new = t_start_new + 1\n",
    "                \n",
    "                # The array that contains all 1-sec segments that present the selected keyword\n",
    "                segmentlist = np.concatenate((segmentlist,np.array([[t_start_new, t_end_new]])))\n",
    "                \n",
    "                # The array that contains the location of each keyword in each segment\n",
    "                locations = np.concatenate((locations,np.array([[t_start - t_start_new, t_end - t_start_new]])))\n",
    "\n",
    "        segmentlist = np.delete(segmentlist,0,axis=0)\n",
    "        locations = np.delete(locations,0,axis=0)\n",
    "\n",
    "        y, sr = sf.read(file_dir) # read the original audio\n",
    "\n",
    "        if os.path.exists('./Outputs/{0}'.format(keyword)) == False:\n",
    "            os.mkdir('./Outputs/{0}'.format(keyword))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Generate and save the segments\n",
    "        for i in range(np.shape(segmentlist)[0]):\n",
    "            y_cut = y[int(segmentlist[i,0]*sr) : int(segmentlist[i,1]*sr)]\n",
    "            sf.write('./Outputs/{0}/{1}-{2}.wav'.format(keyword, str(word_idx).zfill(4), str(filecount).zfill(4)), y_cut, sr)\n",
    "            \n",
    "            # generate the .wrd files with the location of each keyword\n",
    "            with open('./Outputs/{0}/{1}-{2}.wrd'.format(keyword, str(word_idx).zfill(4), str(filecount).zfill(4)),'w') as file:\n",
    "                file.write('{0} {1} {2}'.format(int(locations[i,0]*sr), int(locations[i,1]*sr), keyword))\n",
    "            \n",
    "            filecount += 1\n",
    "\n",
    "print('Files are generated successifully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files are separated into train, validation, and test sets.\n"
     ]
    }
   ],
   "source": [
    "# This part can separate the audios into train, val, and test sets.\n",
    "\n",
    "import shutil\n",
    "from shutil import copy2\n",
    "\n",
    "train_ratio = 0.7\n",
    "test_ratio = 0.15\n",
    "\n",
    "if os.path.exists('./newOutputs') == False:\n",
    "    os.mkdir('./newOutputs')\n",
    "\n",
    "train_dir_root = './newOutputs/train'\n",
    "if os.path.exists(train_dir_root) == False:\n",
    "    os.mkdir(train_dir_root)\n",
    "\n",
    "val_dir_root = './newOutputs/validation'\n",
    "if os.path.exists(val_dir_root) == False:\n",
    "    os.mkdir(val_dir_root)\n",
    "\n",
    "test_dir_root = './newOutputs/test'\n",
    "if os.path.exists(test_dir_root) == False:\n",
    "    os.mkdir(test_dir_root)\n",
    "\n",
    "for keyword in KEYWORDS:\n",
    "    file_dir = \"./Outputs/{0}/\".format(keyword)\n",
    "    all_files = os.listdir(file_dir)\n",
    "    name_list = []\n",
    "    for file in all_files:\n",
    "        if file.endswith('.wav'):\n",
    "            name_list.append(file[:-4])\n",
    "    num_audios = len(name_list)\n",
    "    index_list = list(range(num_audios))\n",
    "    random.shuffle(index_list)\n",
    "    num = 0\n",
    "    \n",
    "    train_dir = os.path.join(train_dir_root,keyword)\n",
    "    if os.path.exists(train_dir) == False:\n",
    "        os.mkdir(train_dir)\n",
    "    \n",
    "    val_dir = os.path.join(val_dir_root,keyword)\n",
    "    if os.path.exists(val_dir) == False:\n",
    "        os.mkdir(val_dir)\n",
    "    \n",
    "    test_dir = os.path.join(test_dir_root,keyword)\n",
    "    if os.path.exists(test_dir) == False:\n",
    "        os.mkdir(test_dir)\n",
    "    \n",
    "    for i in index_list:\n",
    "        audio_files = os.path.join(file_dir, name_list[i] + '.wav')\n",
    "        wrd_files = os.path.join(file_dir, name_list[i] + '.wrd')\n",
    "        if num < num_audios*train_ratio:\n",
    "            copy2(audio_files, train_dir)\n",
    "            copy2(wrd_files, train_dir)\n",
    "        elif num >= num_audios*(1-test_ratio):\n",
    "            copy2(audio_files, test_dir)\n",
    "            copy2(wrd_files, test_dir)\n",
    "        else:\n",
    "            copy2(audio_files, val_dir)\n",
    "            copy2(wrd_files, val_dir)\n",
    "        num += 1\n",
    "        \n",
    "print('Files are separated into train, validation, and test sets.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
