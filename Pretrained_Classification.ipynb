{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from tensorflow.keras import backend as K\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from random import getrandbits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG11():\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(160,101,1)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(30)\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_onoff():                # randomly turns on or off\n",
    "    return bool(getrandbits(1))\n",
    "\n",
    "\n",
    "def augment_signal(y, sr, quiet=True):\n",
    "    count_changes = 0\n",
    "    allow_pitch, allow_dyn, allow_noise = True, True, True\n",
    "    y_mod = y\n",
    "    # change pitch (w/o speed)\n",
    "    if (allow_pitch) and random_onoff():\n",
    "        bins_per_octave = 24  # pitch increments are quarter-steps\n",
    "        pitch_pm = 4  # +/- this many quarter steps\n",
    "        pitch_change = pitch_pm * 2 * (np.random.uniform() - 0.5)\n",
    "        if not quiet:\n",
    "            print(\"    pitch_change = \", pitch_change)\n",
    "        y_mod = librosa.effects.pitch_shift(y, sr, n_steps=pitch_change, bins_per_octave=bins_per_octave)\n",
    "        count_changes += 1\n",
    "    # change dynamic range\n",
    "    if (allow_dyn) and random_onoff():\n",
    "        dyn_change = np.random.uniform(low=0.5, high=1.1)  # change amplitude\n",
    "        if not quiet:\n",
    "            print(\"    dyn_change = \", dyn_change)\n",
    "        y_mod = y_mod * dyn_change\n",
    "        count_changes += 1\n",
    "        # add noise\n",
    "    if (allow_noise) and random_onoff():\n",
    "        noise_amp = 0.005 * np.random.uniform() * np.amax(y)\n",
    "        if random_onoff():\n",
    "            if not quiet:\n",
    "                print(\"    gaussian noise_amp = \", noise_amp)\n",
    "            y_mod += noise_amp * np.random.normal(size=len(y))\n",
    "        else:\n",
    "            if not quiet:\n",
    "                print(\"    uniform noise_amp = \", noise_amp)\n",
    "            y_mod += noise_amp * np.random.uniform(size=len(y))\n",
    "        count_changes += 1\n",
    "\n",
    "    # last-ditch effort to make sure we made a change (recursive/sloppy, but...works)\n",
    "    if (0 == count_changes):\n",
    "        if not quiet:\n",
    "            print(\"No changes made to signal, trying again\")\n",
    "        y_mod = augment_signal(y_mod, sr, quiet=quiet)\n",
    "\n",
    "    return y_mod\n",
    "\n",
    "\n",
    "def spect_loader(path, window_size=.02, window_stride=.01, window='hamming', normalize=True, max_len=101, augment=False):\n",
    "    y, sr = sf.read(path)\n",
    "    y_original_len = len(y)\n",
    "    \n",
    "    if augment:\n",
    "        y = augment_signal(y, sr)\n",
    "    if not len(y) == y_original_len:\n",
    "        print('augmentation ruined the audio files length!!!')\n",
    "        exit()\n",
    "    \n",
    "    try:\n",
    "        n_fft = int(sr * window_size)\n",
    "    except:\n",
    "        print(path)\n",
    "\n",
    "    win_length = n_fft\n",
    "    hop_length = int(sr * window_stride)\n",
    "    \n",
    "    # STFT\n",
    "    D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window)\n",
    "    \n",
    "    spect, phase = librosa.magphase(D)\n",
    "    spect = np.log1p(spect)\n",
    "    real_features_len = spect.shape[1]\n",
    "    \n",
    "    # make all spects with the same dims\n",
    "    if spect.shape[1] < max_len:\n",
    "        pad = np.zeros((spect.shape[0], max_len - spect.shape[1]))\n",
    "        spect = np.hstack((spect, pad))\n",
    "    elif spect.shape[1] > max_len:\n",
    "        spect = spect[:, :max_len]\n",
    "\n",
    "    if spect.shape[0] < 160:\n",
    "        pad = np.zeros((160 - spect.shape[0], spect.shape[1]))\n",
    "        spect = np.vstack((spect, pad))\n",
    "    elif spect.shape[0] > 160:\n",
    "        spect = spect[:160, :]\n",
    "    spect = np.resize(spect, (spect.shape[0], spect.shape[1], 1))\n",
    "    #spect = torch.FloatTensor(spect) \n",
    "    \n",
    "    #normalization to zero-mean and one-std\n",
    "    normalize = True\n",
    "    if normalize:\n",
    "        mean = np.mean(spect)\n",
    "        std = np.std(spect)\n",
    "        if std != 0:\n",
    "            spect = spect - mean\n",
    "            spect = spect / std\n",
    "            \n",
    "    return spect, len(y), real_features_len, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_classes(dir):\n",
    "    classes = [d for d in os.listdir(dir) if (os.path.isdir(os.path.join(dir, d)))]\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "AUDIO_EXTENSIONS = ['.wav', '.WAV']\n",
    "\n",
    "def is_audio_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in AUDIO_EXTENSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataLoader(path, window_size, window_stride, window_type, normalize, max_len):\n",
    "    classes, class_to_idx = find_classes(path)\n",
    "\n",
    "    spects = []\n",
    "    root_dir = os.path.expanduser(path)\n",
    "    count = 0\n",
    "\n",
    "    for data in sorted(os.listdir(root_dir)):\n",
    "        d = os.path.join(root_dir, data)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "        for root, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in sorted(fnames):\n",
    "                if is_audio_file(fname):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    label = os.path.join(root, fname.replace(\".wav\", \".wrd\"))\n",
    "                    item = (path, class_to_idx[data], label)\n",
    "                    spects.append(item)\n",
    "                    count += 1\n",
    "\n",
    "    if len(spects) == 0:\n",
    "        raise (RuntimeError(\"Found 0 sound files in subfolders of: \" + path + \"Supported audio file extensions are: \" + \",\".join(AUDIO_EXTENSIONS)))\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for index in range(np.shape(spects)[0]):\n",
    "        data_dir, target, label_path = spects[index]\n",
    "        spect, _, _, _ = spect_loader(data_dir, window_size, window_stride, window_type, normalize, max_len)\n",
    "        dataset.append((spect, target))\n",
    "    \n",
    "    features = np.zeros([np.shape(dataset)[0]] + list(np.shape(dataset[0][0])))\n",
    "    labels = np.zeros([np.shape(dataset)[0],30])\n",
    "    \n",
    "    for i in range(np.shape(dataset)[0]):\n",
    "        labels[i,dataset[i][1]] = 1\n",
    "        features[i,:,:,:] = dataset[i][0]\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(arc='VGG11', batch_size=32, class_num=30, cuda=True, epochs=100, log_interval=100, lr=0.001, max_len=101, momentum=0.9, normalize=True, optimizer='adam', patience=5, save_folder='gcommand_pretraining_model/', seed=1234, test_batch_size=100, test_path='gcommand_toy_example/test', train_path='gcommand_toy_example/train', valid_path='gcommand_toy_example/valid', window_size=0.02, window_stride=0.01, window_type='hamming')\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='ConvNets for Speech Commands Recognition')\n",
    "parser.add_argument('--train_path', default='gcommand_toy_example/train',\n",
    "                    help='path to the train data folder')\n",
    "parser.add_argument('--test_path', default='gcommand_toy_example/test',\n",
    "                    help='path to the test data folder')\n",
    "parser.add_argument('--valid_path', default='gcommand_toy_example/valid',\n",
    "                    help='path to the valid data folder')\n",
    "parser.add_argument('--batch_size', type=int, default=32,\n",
    "                    metavar='N', help='training and valid batch size')\n",
    "parser.add_argument('--test_batch_size', type=int, default=100,\n",
    "                    metavar='N', help='batch size for testing')\n",
    "parser.add_argument('--arc', default='VGG11',\n",
    "                    help='network architecture: VGG11, VGG13, VGG16, VGG19')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    metavar='N', help='number of epochs to train')\n",
    "parser.add_argument('--lr', type=float, default=0.001,\n",
    "                    metavar='LR', help='learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                    metavar='M', help='SGD momentum, for SGD only')\n",
    "parser.add_argument('--optimizer', default='adam',\n",
    "                    help='optimization method: sgd | adam')\n",
    "parser.add_argument('--cuda', default=True, help='enable CUDA')\n",
    "parser.add_argument('--seed', type=int, default=1234,\n",
    "                    metavar='S', help='random seed')\n",
    "parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n",
    "                    help='num of batches to wait until logging train status')\n",
    "parser.add_argument('--patience', type=int, default=5, metavar='N',\n",
    "                    help='how many epochs of no loss improvement should we wait before stop training')\n",
    "\n",
    "# feature extraction options\n",
    "parser.add_argument('--max_len', type=int, default=101,\n",
    "                    help='window size for the stft')\n",
    "parser.add_argument('--window_size', default=.02,\n",
    "                    help='window size for the stft')\n",
    "parser.add_argument('--window_stride', default=.01,\n",
    "                    help='window stride for the stft')\n",
    "parser.add_argument('--window_type', default='hamming',\n",
    "                    help='window type for the stft')\n",
    "parser.add_argument('--normalize', default=True,\n",
    "                    help='boolean, wheather or not to normalize the spect')\n",
    "parser.add_argument('--save_folder', type=str,  default='gcommand_pretraining_model/',\n",
    "                    help='path to save the final model')\n",
    "parser.add_argument('--class_num', type=int,  default=30,\n",
    "                    help='number of classes to classify')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, labels_train = DataLoader(args.train_path, window_size=args.window_size, window_stride=args.window_stride, \n",
    "                           window_type=args.window_type, normalize=args.normalize, max_len=args.max_len)\n",
    "\n",
    "data_val, labels_val = DataLoader(args.valid_path, window_size=args.window_size, window_stride=args.window_stride, \n",
    "                           window_type=args.window_type, normalize=args.normalize, max_len=args.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = VGG11()\n",
    "clf.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "clf_train = clf.fit(data_train, labels_train, validation_data=(data_val, labels_val), epochs=1, batch_size=1, shuffle=True)\n",
    "scores = clf.evaluate(data_val, labels_val)\n",
    "print(\"Accuracy: %.2f%%\" %(scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-tf2",
   "language": "python",
   "name": "py37-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
